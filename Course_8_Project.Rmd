---
title: "Course 8 Project"
author: "By Rick Toothill"
output: html_document
---

# Overview
The "quantified self" movement focuses on recording information about an individual's physical activity.  The goal is to promote health or just "geek out" over collecting the data.  Devices such as Fitbit and Nike FuelBank capture such information.  This approach is effective in recording activity, but not as effective in measuring quality of the activity.  The goals of this project is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 individuals to predict the quality of their activity.

# Data Exploration
We will begin by loading both the train and test datasets.  Note that our outcome variable, "classe", is explicitly defined as a factor. 
```{r}
library("caret")

## Establish working director & load training data
wkdir <- "c:/Users/toothill/Desktop/Course 8 - Practical Machine Learning/Project/"
fit_train <- read.csv(paste(wkdir, "pml-training.csv", sep=""), na.strings=c("NA",""), stringsAsFactors=FALSE)
fit_test <- read.csv(paste(wkdir, "pml-testing.csv", sep=""), na.strings=c("NA",""), stringsAsFactors=FALSE)

fit_train$classe <- as.factor(fit_train$classe)
```

The next step is to explore the data to determine the most useful columns for prediction.  Several columns are excluded for various reason as you can see below.  A variable is included in the model only if it has a value (ie. is not "na") in more than 19,000 instances.
```{r}
## Eliminate the unnecessary columns - usernames, times, dates, etc.
fit_train <- fit_train[,7:160]
fit_test <- fit_test[,7:160]

## Identify the columns with fewer na's
few_nas <- apply(!is.na(fit_train), 2, sum) > 19000

## Eliminate columns with mostly na's
fit_train <- fit_train[,few_nas]
fit_test <- fit_test[,few_nas]
```

# Partition Data & Training Model
Next, we partition the training dataset into a training set and a test set.  We only use 30% of the data for training due to performance concerns in R.
```{r}
## Create a training & testing set from training
inTrain <- createDataPartition(y=fit_train$classe,p=0.3,list=FALSE)
fit_train_train <- fit_train[inTrain,]
fit_train_test <- fit_train[-inTrain,]
```

Next, we train the model using Random Forest (rf).  
```{r}
set.seed(3345)

# Train the model with 5 folds of cross-validation
modFit <- train(classe ~ ., data=fit_train_train,method="rf",trControl=trainControl(method="cv",number=10),prox=TRUE,allowParallel=TRUE)

print(modFit)
```
Cross-validation using 10 folds was used to help detect relvant features, estimate various parameters, and build the most acccurate model.  This allows us to refine the model while NOT using the testing data!


# Test the Model & Out of Sample Error
Next, we use this model to predict the test dataset that was held out and create a confusion matrix to determine the Out of Sample Error.
```{r}

# Predict the outcome variable for the held out test set
fit_pred <- predict(modFit,fit_train_test)

# Calculate the out of sample error using the confusion matrix
confusionMatrix(fit_pred,fit_train_test$classe)
```

As can be seen, the Out of Sample error for the model is ~ 0.74%.  This breakdown as follows across the different outcomes:

A - 18 errors, 3922 chances = 0.5%  
B - 19 errors, 2633 chances = 0.7%  
C - 42 errors, 2420 chances = 0.2%  
D - 21 errors, 2255 chances = 0.9%  
E - 1 error, 2503 chances = 0.01%  

# Predict Test Outcomes

```{r}
# Use the above model to make predictions of the test data
pred_test <- predict(modFit,fit_test)
```
This model predicts the following values for the test data: `r pred_test`.